{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "26KJjVGTRAzr"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator       # Para preprocesar imágenes\n",
    "from tensorflow.python.keras import optimizers                                   # Utilizaremos el algoritmo Adam\n",
    "from tensorflow.python.keras.models import Sequential                            # Modelos secuenciales, capas en orden\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation   # Capas para la ConvNet\n",
    "from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D           # Capas para la ConvNet\n",
    "from tensorflow.python.keras import backend as k                                 # Permite gestionar sesiones en background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15943,
     "status": "ok",
     "timestamp": 1571016909104,
     "user": {
      "displayName": "Guillermo Coronado",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB82CsOwLngHLjgxTU9FW1XcYImfs8iLw-2Cxuq=s64",
      "userId": "05803857212941809303"
     },
     "user_tz": 300
    },
    "id": "Ysy_tIx8cruk",
    "outputId": "388829f0-f24d-46d7-d81f-9a85a8fb3b95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# Mount the Google Drive to Google Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1338,
     "status": "ok",
     "timestamp": 1571016949735,
     "user": {
      "displayName": "Guillermo Coronado",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB82CsOwLngHLjgxTU9FW1XcYImfs8iLw-2Cxuq=s64",
      "userId": "05803857212941809303"
     },
     "user_tz": 300
    },
    "id": "fBWMdVeTAmBL",
    "outputId": "b9e376d2-79cf-4815-a54a-9a7a7d1d13ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 344593,
     "status": "error",
     "timestamp": 1571022863803,
     "user": {
      "displayName": "Guillermo Coronado",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB82CsOwLngHLjgxTU9FW1XcYImfs8iLw-2Cxuq=s64",
      "userId": "05803857212941809303"
     },
     "user_tz": 300
    },
    "id": "EtSuaNhNRAz1",
    "outputId": "ca03c745-09b4-4903-ce33-b5460f229472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2043 images belonging to 3 classes.\n",
      "Found 999 images belonging to 3 classes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Epoch 1/20\n",
      " 999/1000 [============================>.] - ETA: 1s - loss: 0.7744 - acc: 0.4882Epoch 1/20\n",
      "1000/1000 [==============================] - 1463s 1s/step - loss: 0.7743 - acc: 0.4884 - val_loss: 0.7883 - val_acc: 0.4578\n",
      "Epoch 2/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7450 - acc: 0.4961Epoch 1/20\n",
      "1000/1000 [==============================] - 233s 233ms/step - loss: 0.7451 - acc: 0.4961 - val_loss: 0.7733 - val_acc: 0.5254\n",
      "Epoch 3/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7450 - acc: 0.4873Epoch 1/20\n",
      "1000/1000 [==============================] - 233s 233ms/step - loss: 0.7450 - acc: 0.4873 - val_loss: 0.7757 - val_acc: 0.4566\n",
      "Epoch 4/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7439 - acc: 0.4921Epoch 1/20\n",
      "1000/1000 [==============================] - 235s 235ms/step - loss: 0.7440 - acc: 0.4920 - val_loss: 0.7762 - val_acc: 0.4550\n",
      "Epoch 5/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7419 - acc: 0.4893Epoch 1/20\n",
      "1000/1000 [==============================] - 234s 234ms/step - loss: 0.7423 - acc: 0.4893 - val_loss: 0.7745 - val_acc: 0.5250\n",
      "Epoch 6/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7420 - acc: 0.4849Epoch 1/20\n",
      "1000/1000 [==============================] - 234s 234ms/step - loss: 0.7420 - acc: 0.4849 - val_loss: 0.7763 - val_acc: 0.5240\n",
      "Epoch 7/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7421 - acc: 0.4904Epoch 1/20\n",
      "1000/1000 [==============================] - 232s 232ms/step - loss: 0.7421 - acc: 0.4903 - val_loss: 0.7809 - val_acc: 0.4550\n",
      "Epoch 8/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7418 - acc: 0.4836Epoch 1/20\n",
      "1000/1000 [==============================] - 234s 234ms/step - loss: 0.7419 - acc: 0.4836 - val_loss: 0.7782 - val_acc: 0.5232\n",
      "Epoch 9/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7418 - acc: 0.4856Epoch 1/20\n",
      "1000/1000 [==============================] - 233s 233ms/step - loss: 0.7418 - acc: 0.4856 - val_loss: 0.7780 - val_acc: 0.4584\n",
      "Epoch 10/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7421 - acc: 0.4903Epoch 1/20\n",
      "1000/1000 [==============================] - 233s 233ms/step - loss: 0.7420 - acc: 0.4902 - val_loss: 0.7769 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7425 - acc: 0.4904Epoch 1/20\n",
      "1000/1000 [==============================] - 232s 232ms/step - loss: 0.7424 - acc: 0.4904 - val_loss: 0.7799 - val_acc: 0.5229\n",
      "Epoch 12/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7418 - acc: 0.4872Epoch 1/20\n",
      "1000/1000 [==============================] - 235s 235ms/step - loss: 0.7418 - acc: 0.4872 - val_loss: 0.7795 - val_acc: 0.4565\n",
      "Epoch 13/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7420 - acc: 0.4904Epoch 1/20\n",
      "1000/1000 [==============================] - 235s 235ms/step - loss: 0.7420 - acc: 0.4904 - val_loss: 0.7837 - val_acc: 0.4552\n",
      "Epoch 14/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7419 - acc: 0.4915Epoch 1/20\n",
      "1000/1000 [==============================] - 234s 234ms/step - loss: 0.7419 - acc: 0.4915 - val_loss: 0.7785 - val_acc: 0.4584\n",
      "Epoch 15/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7421 - acc: 0.4877Epoch 1/20\n",
      "1000/1000 [==============================] - 235s 235ms/step - loss: 0.7421 - acc: 0.4877 - val_loss: 0.7861 - val_acc: 0.4539\n",
      "Epoch 16/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7423 - acc: 0.4858Epoch 1/20\n",
      "1000/1000 [==============================] - 234s 234ms/step - loss: 0.7422 - acc: 0.4858 - val_loss: 0.7788 - val_acc: 0.4568\n",
      "Epoch 17/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7418 - acc: 0.4866Epoch 1/20\n",
      "1000/1000 [==============================] - 232s 232ms/step - loss: 0.7419 - acc: 0.4865 - val_loss: 0.7759 - val_acc: 0.4550\n",
      "Epoch 18/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7418 - acc: 0.4922Epoch 1/20\n",
      "1000/1000 [==============================] - 228s 228ms/step - loss: 0.7418 - acc: 0.4923 - val_loss: 0.7802 - val_acc: 0.5254\n",
      "Epoch 19/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7425 - acc: 0.4886Epoch 1/20\n",
      "1000/1000 [==============================] - 234s 234ms/step - loss: 0.7424 - acc: 0.4887 - val_loss: 0.7766 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.7414 - acc: 0.4866Epoch 1/20\n",
      "1000/1000 [==============================] - 238s 238ms/step - loss: 0.7416 - acc: 0.4865 - val_loss: 0.7825 - val_acc: 0.5251\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-79a88c30b6e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/Colab Notebooks/model/model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected: '/content/gdrive/My Drive/Colab Notebooks/model/'"
     ]
    }
   ],
   "source": [
    "k.clear_session();\n",
    "\n",
    "train_data = '/content/drive/My Drive/Colab Notebooks/data/test'\n",
    "test_data = '/content/drive/My Drive/Colab Notebooks/data/train'\n",
    "\n",
    "# Número de iteraciones sobre todo el dataset de entrenamiento\n",
    "epochs = 20\n",
    "\n",
    "# Dimensiones de las imágenes para procesar\n",
    "n_H, n_W = 100, 100\n",
    "\n",
    "# Utilizaremos mini-batch\n",
    "batch_size = 32\n",
    "\n",
    "# Número de iteraciones que vamos a procesar la información en cada epoca (entrenamiento)\n",
    "steps = 1000\n",
    "\n",
    "# Número de iteraciones que vamos a procesar la información en cada epoca (validación)\n",
    "test_steps = 200\n",
    "\n",
    "# Definamos la tasa de aprendizaje\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Número de clases\n",
    "class_num = 3\n",
    "\n",
    "# Estructura de la red neuronal convolucionales\n",
    "filter_conv1 = 32\n",
    "size_filter1 = (3,3)\n",
    "\n",
    "filter_conv2 = 64\n",
    "size_filter2 = (2,2)\n",
    "\n",
    "#Usaremos un Max Pooling\n",
    "size_pool = (2,2)\n",
    "\n",
    "\n",
    "# 1. Antes de comenzar con el modelo, vamos a preprocesar las imágenes\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    rescale = 1./255,          # Normalizar los valores de los pixeles\n",
    "    shear_range= 0.3,           # Rango del ángulo que podemos inclinar nuestras imágenes\n",
    "    zoom_range = 0.3,            # Rango del zoom que podemos hacer a nuestras imágenes\n",
    "    horizontal_flip = True       # Invierte imágenes\n",
    ")\n",
    "\n",
    "test_data_generator = ImageDataGenerator(\n",
    "    rescale = 1./255           # Normalizar los valores de los pixeles\n",
    ")\n",
    "\n",
    "# Accede al directorio, preprocesa las imágenes y organiza en mini-batchs\n",
    "train_images = train_data_generator.flow_from_directory(\n",
    "    train_data,\n",
    "    target_size = (n_H, n_W),             # Tamaño de las imágenes\n",
    "    batch_size = batch_size,              # Tamaño del mini-batch\n",
    "    class_mode = 'categorical'            # Modelo para clasificación\n",
    ")\n",
    "\n",
    "# Accede al directorio, preprocesa las imágenes y organiza en mini-batchs\n",
    "test_images = test_data_generator.flow_from_directory(\n",
    "    test_data,\n",
    "    target_size = (n_H, n_W),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Crear la ConvNet\n",
    "cnn = Sequential()\n",
    "\n",
    "cnn.add(Convolution2D(filter_conv1, size_filter1, padding='same', input_shape=(n_H, n_W,3), activation='relu'))\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=size_pool))\n",
    "\n",
    "cnn.add(Convolution2D(filter_conv2, size_filter2, padding='same', activation='relu'))\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=size_pool))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "cnn.add(Dense(256, activation='relu'))\n",
    "\n",
    "cnn.add(Dropout(0.5))\n",
    "\n",
    "cnn.add(Dense(class_num, activation='softmax'))\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "\n",
    "cnn.fit(train_images, steps_per_epoch=steps, epochs=epochs, validation_data = test_images, validation_steps=test_steps)\n",
    "\n",
    "# Definamos donde queremos guardar nuestro modelo y los pesos\n",
    "dir='/content/gdrive/My Drive/Colab Notebooks/model/'\n",
    "\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "    \n",
    "cnn.save('/content/gdrive/My Drive/Colab Notebooks/model/model.h5')\n",
    "cnn.save_weights('/content/gdrive/My Drive/Colab Notebooks/model/weights.h5')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "keras_intro.ipynb",
   "provenance": [
    {
     "file_id": "1-SzGPs1Bo7BnPiwhMH66D2uy_9NYXvgD",
     "timestamp": 1570577817835
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
