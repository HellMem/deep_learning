{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAzdusdWtSPb",
    "colab_type": "text"
   },
   "source": [
    "Drive mounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "2A_PSOhJrZ5e",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d52HsVHwtbcc",
    "colab_type": "text"
   },
   "source": [
    "Dependencies importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "4eiUNFOmtps2",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "from __future__ import division, print_function, absolute_import\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "import glob\n",
    "import h5py\n",
    "import cv2\n",
    "from math import ceil\n",
    "\n",
    "from random import shuffle\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%tensorflow_version 1.x\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IllNmTwpt6bi",
    "colab_type": "text"
   },
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Uynn7842qkdI",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "#autoencoder_helpers.py\n",
    "def makedirs(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def list_of_distances(X, Y):\n",
    "    '''\n",
    "    Given a list of vectors, X = [x_1, ..., x_n], and another list of vectors,\n",
    "    Y = [y_1, ... , y_m], we return a list of vectors\n",
    "            [[d(x_1, y_1), d(x_1, y_2), ... , d(x_1, y_m)],\n",
    "             ...\n",
    "             [d(x_n, y_1), d(x_n, y_2), ... , d(x_n, y_m)]],\n",
    "    where the distance metric used is the sqared euclidean distance.\n",
    "    The computation is achieved through a clever use of broadcasting.\n",
    "    '''\n",
    "    XX = tf.reshape(list_of_norms(X), shape=(-1, 1))\n",
    "    YY = tf.reshape(list_of_norms(Y), shape=(1, -1))\n",
    "    output = XX + YY - 2 * tf.matmul(X, tf.transpose(Y))\n",
    "\n",
    "    return output\n",
    "\n",
    "def list_of_norms(X):\n",
    "    '''\n",
    "    X is a list of vectors X = [x_1, ..., x_n], we return\n",
    "        [d(x_1, x_1), d(x_2, x_2), ... , d(x_n, x_n)], where the distance\n",
    "    function is the squared euclidean distance.\n",
    "    '''\n",
    "    return tf.reduce_sum(tf.pow(X, 2), axis=1)\n",
    "\n",
    "def print_and_write(str, file):\n",
    "    print(str)\n",
    "    file.write(str + '\\n')\n",
    "\n",
    "\n",
    "#data_preprocessing.py\n",
    "def batch_elastic_transform(images, sigma, alpha, height, width, random_state=None):\n",
    "    '''\n",
    "    this code is borrowed from chsasank on GitHubGist\n",
    "    Elastic deformation of images as described in [Simard 2003].\n",
    "    \n",
    "    images: a two-dimensional numpy array; we can think of it as a list of flattened images\n",
    "    sigma: the real-valued variance of the gaussian kernel\n",
    "    alpha: a real-value that is multiplied onto the displacement fields\n",
    "    \n",
    "    returns: an elastically distorted image of the same shape\n",
    "    '''\n",
    "    assert len(images.shape) == 2\n",
    "    # the two lines below ensure we do not alter the array images\n",
    "    e_images = np.empty_like(images)\n",
    "    e_images[:] = images\n",
    "    \n",
    "    e_images = e_images.reshape(-1, height, width)\n",
    "    \n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState(None)\n",
    "    x, y = np.mgrid[0:height, 0:width]\n",
    "    \n",
    "    for i in range(e_images.shape[0]):\n",
    "        \n",
    "        dx = gaussian_filter((random_state.rand(height, width) * 2 - 1), sigma, mode='constant') * alpha\n",
    "        dy = gaussian_filter((random_state.rand(height, width) * 2 - 1), sigma, mode='constant') * alpha\n",
    "        indices = x + dx, y + dy\n",
    "        e_images[i] = map_coordinates(e_images[i], indices, order=1)\n",
    "\n",
    "    return e_images.reshape(-1, 196608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "xeq7SDLqVCRh",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def get_onehot_encoder(labels):\n",
    "    values = array(labels).reshape(-1, 1)\n",
    "    # integer-binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, dtype=np.uint8, categories='auto')\n",
    "    onehot_encoder.fit(values)\n",
    "    return onehot_encoder\n",
    "\n",
    "def get_onehot(labels, onehot_encoder):\n",
    "    values = array(labels).reshape(-1, 1)\n",
    "    onehot_encoded = onehot_encoder.transform(values)\n",
    "    return onehot_encoded\n",
    "    \n",
    "def get_onehot_inverse(onehot_label, onehot_encoder):\n",
    "    # invert first example\n",
    "    if len(onehot_label.shape) == 1:\n",
    "        onehot_label = onehot_label.reshape(1,-1)\n",
    "    values = array(onehot_label)\n",
    "    inverted = onehot_encoder.inverse_transform(onehot_label)\n",
    "    return inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "c9eJjdy9QI5J",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "class Animals:\n",
    "  def __init__(self, train_images, val_images, test_images, train_labels, val_labels, test_labels):\n",
    "    self.train_images = train_images\n",
    "    self.val_images = val_images\n",
    "    self.test_images = test_images\n",
    "    self.train_labels = train_labels\n",
    "    self.val_labels = val_labels\n",
    "    self.test_labels = test_labels\n",
    "    self.current_train_batch_index = 0\n",
    "    self.current_val_batch_index = 0\n",
    "    self.current_test_batch_index = 0\n",
    "\n",
    "    self.onehot_encoder = get_onehot_encoder(train_labels)\n",
    "    self.train_labels_onehot_encoded= get_onehot(train_labels, self.onehot_encoder)\n",
    "    self.val_labels_onehot_encoded= get_onehot(val_labels, self.onehot_encoder)\n",
    "    self.test_labels_onehot_encoded= get_onehot(test_labels, self.onehot_encoder)\n",
    "\n",
    "  def train_size(self):\n",
    "    return len(self.train_images)\n",
    "\n",
    "  def val_size(self):\n",
    "    return len(self.val_images)\n",
    "\n",
    "  def test_size(self):\n",
    "    return len(self.test_images)\n",
    "\n",
    "  def train_examples(self, examples_size):\n",
    "    train_examples = self.train_images[:examples_size]\n",
    "    reshaped_examples = []\n",
    "    for x in train_examples:\n",
    "      x = x.reshape(-1)\n",
    "      reshaped_examples.append(x)\n",
    "    return np.array(reshaped_examples)\n",
    "\n",
    "  def all_test_examples(self):\n",
    "    reshaped_examples = []\n",
    "    for x in self.test_images:\n",
    "      x = x.reshape(-1)\n",
    "      reshaped_examples.append(x)\n",
    "    return np.array(reshaped_examples), self.test_labels_onehot_encoded    \n",
    "\n",
    "  def next_train_batch(self, batch_size):\n",
    "    train_images = self.train_images[self.current_train_batch_index: self.current_train_batch_index + batch_size]\n",
    "    #train_labels = self.train_labels[self.current_train_batch_index: self.current_train_batch_index + batch_size]\n",
    "    train_labels = self.train_labels_onehot_encoded[self.current_train_batch_index: self.current_train_batch_index + batch_size]\n",
    "    self.current_train_batch_index += batch_size\n",
    "    reshaped_batch = []\n",
    "    for x in train_images:\n",
    "      x = x.reshape(-1) \n",
    "      reshaped_batch.append(x)\n",
    "\n",
    "    return np.array(reshaped_batch), train_labels\n",
    "\n",
    "  def next_val_batch(self, batch_size):\n",
    "    val_images = self.val_images[self.current_val_batch_index: self.current_val_batch_index + batch_size]\n",
    "    #val_labels = self.val_labels[self.current_val_batch_index: self.current_val_batch_index + batch_size]\n",
    "    val_labels = self.val_labels_onehot_encoded[self.current_val_batch_index: self.current_val_batch_index + batch_size]\n",
    "    self.current_val_batch_index += batch_size\n",
    "    reshaped_batch = []\n",
    "    for x in val_images:\n",
    "      x = x.reshape(-1) \n",
    "      reshaped_batch.append(x)\n",
    "\n",
    "    return np.array(reshaped_batch), val_labels\n",
    "\n",
    "  def next_test_batch(self, batch_size):\n",
    "    test_images = self.test_images[self.current_test_batch_index: self.current_test_batch_index + batch_size]\n",
    "    #test_labels = self.test_labels[self.current_test_batch_index: self.current_test_batch_index + batch_size]\n",
    "    test_labels = self.test_labels_onehot_encoded[self.current_test_batch_index: self.current_test_batch_index + batch_size]\n",
    "    self.current_test_batch_index += batch_size\n",
    "    reshaped_batch = []\n",
    "    for x in test_images:\n",
    "      x = x.reshape(-1) \n",
    "      reshaped_batch.append(x)\n",
    "\n",
    "    return np.array(reshaped_batch), test_labels\n",
    "\n",
    "  def reset_batches(self):\n",
    "    self.current_train_batch_index = 0\n",
    "    self.current_val_batch_index = 0\n",
    "    self.current_test_batch_index = 0\n",
    "\n",
    "  def reset_train_batch(self):\n",
    "    self.current_train_batch_index = 0\n",
    "\n",
    "  def reset_test_batch(self):\n",
    "    self.current_test_batch_index = 0\n",
    "\n",
    "  def reset_val_batch(self):\n",
    "    self.current_val_batch_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "sjZs4bgoIc_3",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "hdf5_path = '/content/drive/My Drive/Colab Notebooks/animals/animals.h5'\n",
    "hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "train_images = hdf5_file[\"train_img\"]\n",
    "val_images = hdf5_file[\"val_img\"]\n",
    "test_images = hdf5_file[\"test_img\"]\n",
    "\n",
    "train_labels = hdf5_file[\"train_labels\"]\n",
    "val_labels = hdf5_file[\"val_labels\"]\n",
    "test_labels = hdf5_file[\"test_labels\"]\n",
    "\n",
    "\n",
    "animals= Animals(train_images, val_images, test_images, train_labels, val_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "d_IFNfbMuTM9",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "#GPUID = 1\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPUID)\n",
    "\n",
    "# the directory to save the model\n",
    "model_folder = os.path.join(os.getcwd(), \"saved_model\", \"animals_model\", \"animals_cae_1\")\n",
    "makedirs(model_folder)\n",
    "img_folder = os.path.join(model_folder, \"img\")\n",
    "makedirs(img_folder)\n",
    "model_filename = \"animals_cae\"\n",
    "# the maximum number of model snapshots we allow tensorflow to save to disk\n",
    "# when set to None there is no limit\n",
    "n_saves = None\n",
    "# console_log is the handle to a text file that records the console output\n",
    "console_log = open(os.path.join(model_folder, \"console_log.txt\"), \"w+\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Hbrsrvg5uadk",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# training parameters\n",
    "learning_rate = 0.02\n",
    "training_epochs = 10\n",
    "batch_size = 1000       # the size of a minibatch\n",
    "test_display_step = 5   # how many epochs we do evaluate on the test set once\n",
    "save_step = 5            # how frequently do we save the model to disk\n",
    "\n",
    "# elastic deformation parameters\n",
    "sigma = 4\n",
    "alpha = 20\n",
    "\n",
    "# lambda's are the ratios between the four error terms\n",
    "lambda_class = 1\n",
    "lambda_ae = 1\n",
    "lambda_1 = 1              # 1 and 2 here corresponds to the notation we used in the paper\n",
    "lambda_2 = 1\n",
    "\n",
    "\n",
    "input_height = 256         # data input shape\n",
    "input_width = input_height\n",
    "n_input_channel = 3       # the number of color channels; 3 for each color in RGB\n",
    "input_size = input_height * input_width * n_input_channel   # the number of pixels in one input image\n",
    "n_classes = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_prototypes = 15         # the number of prototypes\n",
    "n_layers = 4\n",
    "\n",
    "# height and width of each layers' filters\n",
    "f_1 = 3\n",
    "f_2 = 3\n",
    "f_3 = 3\n",
    "f_4 = 3\n",
    "\n",
    "# stride size in each direction for each of the layers\n",
    "s_1 = 2\n",
    "s_2 = 2\n",
    "s_3 = 2\n",
    "s_4 = 2\n",
    "\n",
    "# number of feature maps in each layer\n",
    "n_map_1 = 30\n",
    "n_map_2 = 30\n",
    "n_map_3 = 30\n",
    "n_map_4 = 30\n",
    "\n",
    "# the shapes of each layer's filter\n",
    "filter_shape_1 = [f_1, f_1, n_input_channel, n_map_1]\n",
    "filter_shape_2 = [f_2, f_2, n_map_1, n_map_2]\n",
    "filter_shape_3 = [f_3, f_3, n_map_2, n_map_3]\n",
    "filter_shape_4 = [f_4, f_4, n_map_3, n_map_4]\n",
    "\n",
    "stride_1 = [1, s_1, s_1, 1]\n",
    "stride_2 = [1, s_2, s_2, 1]\n",
    "stride_3 = [1, s_3, s_3, 1]\n",
    "stride_4 = [1, s_4, s_4, 1]\n",
    "\n",
    "# tf Graph input\n",
    "# X is the 2-dimensional matrix whose every row is an image example.\n",
    "# Y is the 2-dimensional matrix whose every row is the one-hot encoding label.\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, input_size], name='X')\n",
    "X_img = tf.reshape(X, shape=[-1, input_height, input_width, n_input_channel], name='X_img')\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, n_classes], name='Y')\n",
    "\n",
    "# We create a tf placeholder for every lambda so that they can be tweaked during training\n",
    "lambda_class_t = tf.placeholder(dtype=tf.float32, shape=(), name=\"lambda_class_t\")\n",
    "lambda_ae_t = tf.placeholder(dtype=tf.float32, shape=(), name=\"lambda_ae_t\")\n",
    "lambda_2_t = tf.placeholder(dtype=tf.float32, shape=(), name=\"lambda_2_t\")\n",
    "lambda_1_t = tf.placeholder(dtype=tf.float32, shape=(), name=\"lambda_1_t\")\n",
    "\n",
    "weights = {\n",
    "    'enc_f1': tf.Variable(tf.random_normal(filter_shape_1,\n",
    "                                           stddev=0.01,\n",
    "                                           dtype=tf.float32),\n",
    "                          name='encoder_f1'),\n",
    "    'enc_f2': tf.Variable(tf.random_normal(filter_shape_2,\n",
    "                                           stddev=0.01,\n",
    "                                           dtype=tf.float32),\n",
    "                          name='encoder_f2'),\n",
    "    'enc_f3': tf.Variable(tf.random_normal(filter_shape_3,\n",
    "                                           stddev=0.01,\n",
    "                                           dtype=tf.float32),\n",
    "                          name='encoder_f3'),\n",
    "    'enc_f4': tf.Variable(tf.random_normal(filter_shape_4,\n",
    "                                           stddev=0.01,\n",
    "                                           dtype=tf.float32),\n",
    "                          name='encoder_f4'),\n",
    "    'dec_f4': tf.Variable(tf.random_normal(filter_shape_4,\n",
    "                                           stddev=0.01,\n",
    "                                           dtype=tf.float32),\n",
    "                          name='decoder_f4'),\n",
    "    'dec_f3': tf.Variable(tf.random_normal(filter_shape_3,\n",
    "                                           stddev=0.01,\n",
    "                                           dtype=tf.float32),\n",
    "                          name='decoder_f3'),\n",
    "    'dec_f2': tf.Variable(tf.random_normal(filter_shape_2,\n",
    "                                           stddev=0.01,\n",
    "                                           dtype=tf.float32),\n",
    "                          name='decoder_f2'),\n",
    "    'dec_f1': tf.Variable(tf.random_normal(filter_shape_1,\n",
    "                                           stddev=0.01,\n",
    "                                           dtype=tf.float32),\n",
    "                          name='decoder_f1')\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'enc_b1': tf.Variable(tf.zeros([n_map_1], dtype=tf.float32),\n",
    "                          name='encoder_b1'),\n",
    "    'enc_b2': tf.Variable(tf.zeros([n_map_2], dtype=tf.float32),\n",
    "                          name='encoder_b2'),\n",
    "    'enc_b3': tf.Variable(tf.zeros([n_map_3], dtype=tf.float32),\n",
    "                          name='encoder_b3'),\n",
    "    'enc_b4': tf.Variable(tf.zeros([n_map_4], dtype=tf.float32),\n",
    "                          name='encoder_b4'),\n",
    "    'dec_b4': tf.Variable(tf.zeros([n_map_3], dtype=tf.float32),\n",
    "                          name='decoder_b4'),\n",
    "    'dec_b3': tf.Variable(tf.zeros([n_map_2], dtype=tf.float32),\n",
    "                          name='decoder_b3'),\n",
    "    'dec_b2': tf.Variable(tf.zeros([n_map_1], dtype=tf.float32),\n",
    "                          name='decoder_b2'),\n",
    "    'dec_b1': tf.Variable(tf.zeros([n_input_channel], dtype=tf.float32),\n",
    "                          name='decoder_b1')\n",
    "}\n",
    "\n",
    "last_layer = {\n",
    "    'w': tf.Variable(tf.random_uniform(shape=[n_prototypes, n_classes],\n",
    "                                       dtype=tf.float32),\n",
    "                     name='last_layer_w')\n",
    "}\n",
    "\n",
    "# padding can be either \"SAME\" or \"VALID\"\n",
    "def conv_layer(input, filter, bias, strides, padding=\"VALID\", nonlinearity=tf.nn.relu):\n",
    "    conv = tf.nn.conv2d(input, filter, strides=strides, padding=padding)\n",
    "    act = nonlinearity(conv + bias)\n",
    "    return act\n",
    "\n",
    "# tensorflow's conv2d_transpose needs to know the shape of the output\n",
    "def deconv_layer(input, filter, bias, output_shape, strides, padding=\"VALID\", nonlinearity=tf.nn.relu):\n",
    "    deconv = tf.nn.conv2d_transpose(input, filter, output_shape, strides, padding=padding)\n",
    "    act = nonlinearity(deconv + bias)\n",
    "    return act\n",
    "\n",
    "def fc_layer(input, weight, bias, nonlinearity=tf.nn.relu):\n",
    "    return nonlinearity(tf.matmul(input, weight) + bias)\n",
    "\n",
    "# construct the model\n",
    "# eln means the output of the nth layer of the encoder\n",
    "el1 = conv_layer(X_img, weights['enc_f1'], biases['enc_b1'], stride_1, \"SAME\")\n",
    "el2 = conv_layer(el1, weights['enc_f2'], biases['enc_b2'], stride_2, \"SAME\")\n",
    "el3 = conv_layer(el2, weights['enc_f3'], biases['enc_b3'], stride_3, \"SAME\")\n",
    "el4 = conv_layer(el3, weights['enc_f4'], biases['enc_b4'], stride_4, \"SAME\")\n",
    "\n",
    "# we compute the output shape of each layer because the deconv_layer function requires it\n",
    "l1_shape = el1.get_shape().as_list()\n",
    "l2_shape = el2.get_shape().as_list()\n",
    "l3_shape = el3.get_shape().as_list()\n",
    "l4_shape = el4.get_shape().as_list()\n",
    "\n",
    "flatten_size = l4_shape[1] * l4_shape[2] * l4_shape[3]\n",
    "n_features = flatten_size\n",
    "# feature vectors is the flattened output of the encoder\n",
    "feature_vectors = tf.reshape(el4, shape=[-1, flatten_size], name='feature_vectors')\n",
    "\n",
    "# the list prototype feature vectors\n",
    "prototype_feature_vectors = tf.Variable(tf.random_uniform(shape=[n_prototypes, n_features],\n",
    "                                                          dtype=tf.float32),\n",
    "                                        name='prototype_feature_vectors')\n",
    "\n",
    "'''deconv_batch_size is the number of feature vectors in the batch going into\n",
    "the deconvolutional network. This is required by the signature of\n",
    "conv2d_transpose. But instead of feeding in the value, the size is infered during\n",
    "sess.run by looking at how many rows the feature_vectors matrix has\n",
    "'''\n",
    "deconv_batch_size = tf.identity(tf.shape(feature_vectors)[0], name=\"deconv_batch_size\")\n",
    "\n",
    "# this is necessary for prototype images evaluation\n",
    "reshape_feature_vectors = tf.reshape(feature_vectors, shape=[-1, l4_shape[1], l4_shape[2], l4_shape[3]])\n",
    "\n",
    "# dln means the output of the nth layer of the decoder\n",
    "dl4 = deconv_layer(reshape_feature_vectors, weights['dec_f4'], biases['dec_b4'],\n",
    "                   output_shape=[deconv_batch_size, l3_shape[1], l3_shape[2], l3_shape[3]],\n",
    "                   strides=stride_4, padding=\"SAME\")\n",
    "dl3 = deconv_layer(dl4, weights['dec_f3'], biases['dec_b3'],\n",
    "                   output_shape=[deconv_batch_size, l2_shape[1], l2_shape[2], l2_shape[3]],\n",
    "                   strides=stride_3, padding=\"SAME\")\n",
    "dl2 = deconv_layer(dl3, weights['dec_f2'], biases['dec_b2'],\n",
    "                   output_shape=[deconv_batch_size, l1_shape[1], l1_shape[2], l1_shape[3]],\n",
    "                   strides=stride_2, padding=\"SAME\")\n",
    "dl1 = deconv_layer(dl2, weights['dec_f1'], biases['dec_b1'],\n",
    "                   output_shape=[deconv_batch_size, input_height, input_width, n_input_channel],\n",
    "                   strides=stride_1, padding=\"SAME\", nonlinearity=tf.nn.sigmoid)\n",
    "'''\n",
    "X_decoded is the decoding of the encoded feature vectors in X;\n",
    "we reshape it to match the shape of the training input\n",
    "X_true is the correct output for the autoencoder\n",
    "'''\n",
    "X_decoded = tf.reshape(dl1, shape=[-1, input_size], name='X_decoded')\n",
    "X_true = tf.identity(X, name='X_true')\n",
    "\n",
    "'''\n",
    "prototype_distances is the list of distances from each x_i to every prototype\n",
    "in the latent space\n",
    "feature_vector_distances is the list of distances from each prototype to every x_i\n",
    "in the latent space\n",
    "'''\n",
    "prototype_distances = list_of_distances(feature_vectors,\n",
    "                                        prototype_feature_vectors)\n",
    "prototype_distances = tf.identity(prototype_distances, name='prototype_distances')\n",
    "feature_vector_distances = list_of_distances(prototype_feature_vectors,\n",
    "                                             feature_vectors)\n",
    "feature_vector_distances = tf.identity(feature_vector_distances, name='feature_vector_distances')\n",
    "\n",
    "# the logits are the weighted sum of distances from prototype_distances\n",
    "logits = tf.matmul(prototype_distances, last_layer['w'], name='logits')\n",
    "probability_distribution = tf.nn.softmax(logits=logits,\n",
    "                                         name='probability_distribution')\n",
    "\n",
    "'''\n",
    "the error function consists of 4 terms, the autoencoder loss,\n",
    "the classification loss, and the two requirements that every feature vector in\n",
    "X look like at least one of the prototype feature vectors and every prototype\n",
    "feature vector look like at least one of the feature vectors in X.\n",
    "'''\n",
    "ae_error = tf.reduce_mean(list_of_norms(X_decoded - X_true), name='ae_error')\n",
    "#class_error = tf.losses.softmax_cross_entropy(onehot_labels=Y, logits=logits)\n",
    "class_error = tf.losses.sigmoid_cross_entropy(multi_class_labels=Y, logits=logits) #try this\n",
    "class_error = tf.identity(class_error, name='class_error')\n",
    "error_1 = tf.reduce_mean(tf.reduce_min(feature_vector_distances, axis = 1), name='error_1')\n",
    "error_2 = tf.reduce_mean(tf.reduce_min(prototype_distances, axis = 1), name='error_2')\n",
    "\n",
    "# total_error is the our minimization objective\n",
    "total_error = lambda_class_t * class_error +\\\n",
    "              lambda_ae_t * ae_error + \\\n",
    "              lambda_1_t * error_1 + \\\n",
    "              lambda_2_t * error_2\n",
    "total_error = tf.identity(total_error, name='total_error')\n",
    "\n",
    "# accuracy is not the classification error term; it is the percentage accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1),\n",
    "                              tf.argmax(Y, 1),\n",
    "                              name='correct_prediction')\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype=tf.float32),\n",
    "                          name='accuracy')\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(total_error)\n",
    "#add the optimizer to collection so that we can retrieve the optimizer and resume training\n",
    "tf.add_to_collection(\"optimizer\", optimizer)\n",
    "    \n",
    "# Create the variable init operation and a saver object to store the model\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "hyperparameters = {\n",
    "\t\"learning_rate\": learning_rate,\n",
    "    \"training_epochs\": training_epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"test_display_step\": test_display_step,\n",
    "    \"save_step\": save_step,\n",
    "\n",
    "    \"lambda_class\": lambda_class,\n",
    "    \"lambda_ae\": lambda_ae,\n",
    "    \"lambda_1\": lambda_1,\n",
    "    \"lambda_2\": lambda_2,\n",
    "\n",
    "    \"input_height\": input_height,\n",
    "    \"input_width\": input_width,\n",
    "    \"n_input_channel\": n_input_channel,\n",
    "    \"input_size\": input_size,\n",
    "    \"n_classes\": n_classes,\n",
    "\n",
    "    \"n_prototypes\": n_prototypes,\n",
    "    \"n_layers\": n_layers,\n",
    "\n",
    "    \"f_1\":\tf_1,\n",
    "    \"f_2\":\tf_2,\n",
    "    \"f_3\": \tf_3,\n",
    "    \"f_4\": \tf_4,\n",
    "\n",
    "    \"s_1\" :s_1,\n",
    "    \"s_2\": s_2,\n",
    "    \"s_3\": s_3,\n",
    "    \"s_4\": s_4,\n",
    "\n",
    "    \"n_map_1\": n_map_1,\n",
    "    \"n_map_2\": n_map_2,\n",
    "    \"n_map_3\": n_map_3,\n",
    "    \"n_map_4\": n_map_4,\n",
    "\n",
    "    \"n_features\": n_features,\n",
    "}\n",
    "# save the hyperparameters above in the model snapshot\n",
    "for (name, value) in hyperparameters.items():\n",
    "    tf.add_to_collection('hyperparameters', tf.constant(name=name, value=value))\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=n_saves)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "# the amount of GPU memory our process occupies\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "#with tf.Session(config=config) as sess:\n",
    "with tf.Session() as sess:\n",
    "    #saver.restore(sess, os.path.join(model_folder, 'animals_cae-10'))\n",
    "    sess.run(init)\n",
    "    # we compute the number of batches because both training and evaluation\n",
    "    # happens batch by batch; we do not throw the entire test set onto the GPU\n",
    "    n_train_batch = animals.train_size() // batch_size\n",
    "    n_valid_batch = animals.val_size() // batch_size\n",
    "    n_test_batch = animals.test_size() // batch_size\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        print_and_write(\"#\"*80, console_log)\n",
    "        print_and_write(\"Epoch: %04d\" % (epoch), console_log)\n",
    "        start_time = time.time()\n",
    "        train_ce, train_ae, train_e1, train_e2, train_te, train_ac = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "        # Loop over all batches\n",
    "        for i in range(n_train_batch):\n",
    "            print(f\"Batch: {i}\\t\", end='')\n",
    "            start_batch_time = time.time()\n",
    "            batch_x, batch_y = animals.next_train_batch(batch_size)\n",
    "            elastic_batch_x = batch_elastic_transform(batch_x, sigma=sigma, alpha=alpha, height=input_height, width=input_width)\n",
    "            _, ce, ae, e1, e2, te, ac = sess.run(\n",
    "                                    (optimizer,\n",
    "                                    class_error,\n",
    "                                    ae_error,\n",
    "                                    error_1,\n",
    "                                    error_2,\n",
    "                                    total_error,\n",
    "                                    accuracy),\n",
    "                                    feed_dict={X: elastic_batch_x,\n",
    "                                               Y: batch_y,\n",
    "                                               lambda_class_t: lambda_class,\n",
    "                                               lambda_ae_t: lambda_ae,\n",
    "                                               lambda_1_t: lambda_1,\n",
    "                                               lambda_2_t: lambda_2})\n",
    "            train_ce += (ce/n_train_batch)\n",
    "            train_ae += (ae/n_train_batch)\n",
    "            train_e1 += (e1/n_train_batch)\n",
    "            train_e2 += (e2/n_train_batch)\n",
    "            train_te += (te/n_train_batch)\n",
    "            train_ac += (ac/n_train_batch)\n",
    "            end_batch_time = time.time()\n",
    "            print('took {0:.2f} seconds.'.format((end_batch_time - start_batch_time)))\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        print_and_write('training takes {0:.2f} seconds.'.format((end_time - start_time)), console_log)\n",
    "        # after every epoch, check the error terms on the entire training set\n",
    "        print_and_write(\"training set errors:\", console_log)\n",
    "        print_and_write(\"\\tclassification error: {:.6f}\".format(train_ce), console_log)\n",
    "        print_and_write(\"\\tautoencoder error: {:.6f}\".format(train_ae), console_log)\n",
    "        print_and_write(\"\\terror_1: {:.6f}\".format(train_e1), console_log)\n",
    "        print_and_write(\"\\terror_2: {:.6f}\".format(train_e2), console_log)\n",
    "        print_and_write(\"\\ttotal error: {:.6f}\".format(train_te), console_log)\n",
    "        print_and_write(\"\\taccuracy: {:.4f}\".format(train_ac), console_log)\n",
    "\n",
    "        \n",
    "        # validation set error terms evaluation\n",
    "        valid_ce, valid_ae, valid_e1, valid_e2, valid_te, valid_ac = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "        # Loop over all batches\n",
    "        for i in range(n_valid_batch):\n",
    "            batch_x, batch_y = animals.next_val_batch(batch_size)\n",
    "            ce, ae, e1, e2, te, ac = sess.run(\n",
    "                                    (class_error,\n",
    "                                    ae_error,\n",
    "                                    error_1,\n",
    "                                    error_2,\n",
    "                                    total_error,\n",
    "                                    accuracy),\n",
    "                                    feed_dict={X: batch_x,\n",
    "                                               Y: batch_y,\n",
    "                                               lambda_class_t: lambda_class,\n",
    "                                               lambda_ae_t: lambda_ae,\n",
    "                                               lambda_2_t: lambda_2,\n",
    "                                               lambda_1_t: lambda_1})\n",
    "            valid_ce += ce/n_valid_batch\n",
    "            valid_ae += ae/n_valid_batch\n",
    "            valid_e1 += e1/n_valid_batch\n",
    "            valid_e2 += e2/n_valid_batch\n",
    "            valid_te += te/n_valid_batch\n",
    "            valid_ac += ac/n_valid_batch\n",
    "\n",
    "        # after every epoch, check the error terms on the entire training set\n",
    "        print_and_write(\"validation set errors:\", console_log)\n",
    "        print_and_write(\"\\tclassification error: {:.6f}\".format(valid_ce), console_log)\n",
    "        print_and_write(\"\\tautoencoder error: {:.6f}\".format(valid_ae), console_log)\n",
    "        print_and_write(\"\\terror_1: {:.6f}\".format(valid_e1), console_log)\n",
    "        print_and_write(\"\\terror_2: {:.6f}\".format(valid_e2), console_log)\n",
    "        print_and_write(\"\\ttotal error: {:.6f}\".format(valid_te), console_log)\n",
    "        print_and_write(\"\\taccuracy: {:.4f}\".format(valid_ac), console_log)\n",
    "        \n",
    "        # test set accuracy evaluation\n",
    "        if epoch % test_display_step == 0 or epoch == training_epochs - 1:\n",
    "            test_ac = 0.0\n",
    "            for i in range(n_test_batch):\n",
    "                batch_x, batch_y = animals.next_test_batch(batch_size)\n",
    "                ac = sess.run(accuracy,\n",
    "                              feed_dict={X: batch_x,\n",
    "                                         Y: batch_y})\n",
    "                test_ac += ac/n_test_batch\n",
    "\n",
    "            # after every epoch, check the error terms on the entire training set\n",
    "            print_and_write(\"test set:\", console_log)\n",
    "            print_and_write(\"\\taccuracy: {:.4f}\".format(test_ac), console_log)\n",
    "\n",
    "        if epoch % save_step == 0 or epoch == training_epochs - 1:\n",
    "            # one .meta file is enough to recover the computational graph\n",
    "            saver.save(sess, os.path.join(model_folder, model_filename),\n",
    "                       global_step=epoch,\n",
    "                       write_meta_graph=(epoch == 0 or epoch == training_epochs - 1))\n",
    "\n",
    "            prototype_imgs = sess.run(X_decoded,\n",
    "                                      feed_dict={feature_vectors: prototype_feature_vectors.eval()})\n",
    "            # visualize the prototype images\n",
    "            n_cols = 5\n",
    "            n_rows = n_prototypes // n_cols + 1 if n_prototypes % n_cols != 0 else n_prototypes // n_cols\n",
    "            g, b = plt.subplots(n_rows, n_cols, figsize=(n_cols, n_rows))\n",
    "            for i in range(n_rows):\n",
    "                for j in range(n_cols):\n",
    "                    if i*n_cols + j < n_prototypes:\n",
    "                        b[i][j].imshow(prototype_imgs[i*n_cols + j].reshape(input_height, input_width, -1),\n",
    "                                        interpolation='none')\n",
    "                        b[i][j].axis('off')\n",
    "                        \n",
    "            plt.savefig(os.path.join(img_folder, 'prototype_result-' + str(epoch) + '.png'),\n",
    "                        transparent=True,\n",
    "                        bbox_inches='tight',\n",
    "                        pad_inches=0)\n",
    "            plt.close()\n",
    "\n",
    "            # Applying encoding and decoding over a small subset of the training set\n",
    "            examples_to_show = 10\n",
    "            encode_decode = sess.run(X_decoded,\n",
    "                                     feed_dict={X: animals.train_examples(examples_to_show)})\n",
    "\n",
    "            # Compare original images with their reconstructions\n",
    "            f, a = plt.subplots(2, examples_to_show, figsize=(examples_to_show, 2))\n",
    "            for i in range(examples_to_show):\n",
    "                a[0][i].imshow(animals.train_images[i].reshape(input_height, input_width, -1),\n",
    "                                interpolation='none')\n",
    "                a[0][i].axis('off')\n",
    "                a[1][i].imshow(encode_decode[i].reshape(input_height, input_width, -1), \n",
    "                                interpolation='none')\n",
    "                a[1][i].axis('off')\n",
    "                \n",
    "            plt.savefig(os.path.join(img_folder, 'decoding_result-' + str(epoch) + '.png'),\n",
    "                        transparent=True,\n",
    "                        bbox_inches='tight',\n",
    "                        pad_inches=0)\n",
    "            plt.close()\n",
    "        animals.reset_batches()\n",
    "    print_and_write(\"Optimization Finished!\", console_log)\n",
    "console_log.close()\n",
    "hdf5_file.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "deep_learning_project.ipynb",
   "provenance": [],
   "private_outputs": true,
   "collapsed_sections": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "TPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
